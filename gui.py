import asyncio
import json
import logging
import os
import re
import shutil
import traceback
import uuid
import zipfile
from glob import escape as glob_escape
from glob import glob

import streamlit as st
from langchain_core.rate_limiters import InMemoryRateLimiter

import minecraft_modpack_auto_translator
from minecraft_modpack_auto_translator import create_resourcepack
from minecraft_modpack_auto_translator.config import (
    DICTIONARY_PREFIX_WHITELIST,
    DICTIONARY_SUFFIX_BLACKLIST,
    DIR_FILTER_WHITELIST,
    OFFICIAL_EN_LANG_FILE,
    OFFICIAL_KO_LANG_FILE,
)
from minecraft_modpack_auto_translator.translator import get_translator

st.set_page_config(
    page_title="ë§ˆì¸í¬ë˜í”„íŠ¸ ëª¨ë“œíŒ© ìë™ ë²ˆì—­ê¸°", page_icon="ğŸ®", layout="wide"
)

logger = logging.getLogger(__name__)
# ë””ë²„ê·¸ ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)

# ì–¸ì–´ ì½”ë“œ ì„¤ì •
# .env íŒŒì¼ì—ì„œ ì–¸ì–´ ì½”ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ "ko_kr"ì…ë‹ˆë‹¤.
LANG_CODE = os.getenv("LANG_CODE", "ko_kr")

# API í‚¤ í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ ë§¤í•‘
API_KEY_ENV_VARS = {
    "OpenAI": "OPENAI_API_KEY",
    "Google": "GOOGLE_API_KEY",
    "Grok": "GROK_API_KEY",
    "Ollama": "OLLAMA_API_KEY",
    "Anthropic": "ANTHROPIC_API_KEY",
}

# API ë² ì´ìŠ¤ URL í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ ë§¤í•‘
API_BASE_ENV_VARS = {
    "OpenAI": "OPENAI_API_BASE",
    "Google": "GOOGLE_API_BASE",
    "Grok": "GROK_API_BASE",
    "Ollama": "OLLAMA_API_BASE",
    "Anthropic": "ANTHROPIC_API_BASE",
}


def get_supported_extensions():
    """ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from minecraft_modpack_auto_translator.parsers.base_parser import BaseParser

    return BaseParser.get_supported_extensions()


def get_parser_by_extension(extension):
    """íŒŒì¼ í™•ì¥ìì— ë§ëŠ” íŒŒì„œ í´ë˜ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from minecraft_modpack_auto_translator.parsers.base_parser import BaseParser

    return BaseParser.get_parser_by_extension(extension)


def add_to_dictionary(
    en_value, ko_value, translation_dictionary, translation_dictionary_lowercase
):
    try:
        if en_value.lower() in translation_dictionary_lowercase:
            target = translation_dictionary[
                translation_dictionary_lowercase[en_value.lower()]
            ]
            if isinstance(target, list):
                if ko_value not in target:
                    translation_dictionary[
                        translation_dictionary_lowercase[en_value.lower()]
                    ].append(ko_value)
            elif isinstance(target, str):
                if (
                    translation_dictionary[
                        translation_dictionary_lowercase[en_value.lower()]
                    ]
                    != ko_value
                ):
                    translation_dictionary[
                        translation_dictionary_lowercase[en_value.lower()]
                    ] = [
                        translation_dictionary[
                            translation_dictionary_lowercase[en_value.lower()]
                        ],
                        ko_value,
                    ]
            else:
                st.error(
                    f"translation_dictionary[{en_value.lower()}]ì˜ íƒ€ì…ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {type(translation_dictionary[en_value.lower()])}"
                )
        else:
            translation_dictionary[en_value] = ko_value
            translation_dictionary_lowercase[en_value.lower()] = en_value

        return translation_dictionary, translation_dictionary_lowercase
    except Exception:
        logger.error(f"ë²ˆì—­ ì‚¬ì „ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {en_value}, {ko_value}")
        error_traceback = traceback.format_exc()
        logger.error(error_traceback)
        return translation_dictionary, translation_dictionary_lowercase


def build_dictionary_from_files(
    en_us_files, modpack_path, translation_dictionary, translation_dictionary_lowercase
):
    """ì˜ì–´ íŒŒì¼ê³¼ í•´ë‹¹í•˜ëŠ” í•œêµ­ì–´ íŒŒì¼ì—ì„œ ë²ˆì—­ ì‚¬ì „ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."""

    file_count = 0
    entries_added = 0

    for en_file in en_us_files:
        try:
            # í•œêµ­ì–´ íŒŒì¼ ê²½ë¡œ ì¶”ì •
            rel_path = en_file.replace(modpack_path, "").lstrip("/\\")
            ko_file = os.path.join(
                modpack_path,
                rel_path.replace("en_us", LANG_CODE).replace("en_US", LANG_CODE),
            )

            # í•œêµ­ì–´ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°
            if os.path.exists(ko_file):
                # íŒŒì¼ ë‚´ìš© ë¡œë“œ
                en_data = extract_lang_content(en_file)
                ko_data = extract_lang_content(ko_file)

                if not isinstance(en_data, dict) or not isinstance(ko_data, dict):
                    continue

                # ë²ˆì—­ ì‚¬ì „ì— ì¶”ê°€
                for key, en_value in en_data.items():
                    if (
                        key in ko_data
                        and isinstance(en_value, str)
                        and isinstance(ko_data[key], str)
                    ):
                        ko_value = ko_data[key]

                        # ë™ì¼í•œ ê°’ì´ë©´ ê±´ë„ˆë›°ê¸°
                        if en_value == ko_value:
                            continue

                        # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸/ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
                        if (
                            key.split(".")[0] in DICTIONARY_PREFIX_WHITELIST
                            and key.split(".")[-1] not in DICTIONARY_SUFFIX_BLACKLIST
                        ):
                            # ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
                            clean_en = en_value.replace("_", "")
                            clean_ko = ko_value.replace("_", "")

                            translation_dictionary, translation_dictionary_lowercase = (
                                add_to_dictionary(
                                    clean_en,
                                    clean_ko,
                                    translation_dictionary,
                                    translation_dictionary_lowercase,
                                )
                            )
                            entries_added += 1

                file_count += 1

        except Exception as e:
            error_traceback = traceback.format_exc()
            st.error(
                f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
            logger.error(error_traceback)

    return (
        translation_dictionary,
        translation_dictionary_lowercase,
        file_count,
        entries_added,
    )


def build_dictionary_from_jar(
    jar_files, translation_dictionary, translation_dictionary_lowercase
):
    """JAR íŒŒì¼ ë‚´ë¶€ì˜ ì–¸ì–´ íŒŒì¼ì—ì„œ ë²ˆì—­ ì‚¬ì „ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."""

    file_count = 0
    entries_added = 0
    supported_extensions = get_supported_extensions()

    for jar_path in jar_files:
        try:
            with zipfile.ZipFile(jar_path, "r") as jar:
                # ì˜ì–´ íŒŒì¼ ì°¾ê¸°
                en_lang_files = [
                    f
                    for f in jar.namelist()
                    if os.path.splitext(f)[1] in supported_extensions
                    and ("en_us" in f.lower() or "en_US" in f.lower())
                ]

                for en_file in en_lang_files:
                    # í•œêµ­ì–´ íŒŒì¼ ê²½ë¡œ ì¶”ì •
                    ko_file = en_file.replace("en_us", LANG_CODE).replace(
                        "en_US", LANG_CODE
                    )

                    # ë‘ íŒŒì¼ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ê²½ìš°
                    if ko_file in jar.namelist():
                        try:
                            # íŒŒì¼ ë‚´ìš© ë¡œë“œ
                            with jar.open(en_file, "r") as f:
                                file_bytes = f.read()
                                en_content = file_bytes.decode("utf-8", errors="ignore")

                            with jar.open(ko_file, "r") as f:
                                file_bytes = f.read()
                                ko_content = file_bytes.decode("utf-8", errors="ignore")

                            # íŒŒì„œë¡œ íŒŒì‹±
                            file_ext = os.path.splitext(en_file)[1]
                            parser_class = get_parser_by_extension(file_ext)

                            if parser_class:
                                en_data = parser_class.load(en_content)
                                ko_data = parser_class.load(ko_content)

                                # ë²ˆì—­ ì‚¬ì „ì— ì¶”ê°€
                                for key, en_value in en_data.items():
                                    if (
                                        key in ko_data
                                        and isinstance(en_value, str)
                                        and isinstance(ko_data[key], str)
                                    ):
                                        ko_value = ko_data[key]

                                        # ë™ì¼í•œ ê°’ì´ë©´ ê±´ë„ˆë›°ê¸°
                                        if en_value == ko_value:
                                            continue

                                        # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸/ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
                                        if (
                                            key.split(".")[0]
                                            in DICTIONARY_PREFIX_WHITELIST
                                            and key.split(".")[-1]
                                            not in DICTIONARY_SUFFIX_BLACKLIST
                                        ):
                                            # ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
                                            clean_en = en_value.replace("_", "")
                                            clean_ko = ko_value.replace("_", "")

                                            (
                                                translation_dictionary,
                                                translation_dictionary_lowercase,
                                            ) = add_to_dictionary(
                                                clean_en,
                                                clean_ko,
                                                translation_dictionary,
                                                translation_dictionary_lowercase,
                                            )
                                            entries_added += 1

                                file_count += 1

                        except Exception as e:
                            st.error(
                                f"JAR íŒŒì¼ ë‚´ë¶€ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {jar_path}, {en_file}, {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
                            )
                            error_traceback = traceback.format_exc()
                            logger.error(error_traceback)

        except Exception as e:
            st.error(
                f"JAR íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {jar_path}, {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
            error_traceback = traceback.format_exc()
            logger.error(error_traceback)

    return (
        translation_dictionary,
        translation_dictionary_lowercase,
        file_count,
        entries_added,
    )


# ê²½ë¡œ íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬ ë° ì •ê·œí™”
def normalize_glob_path(path):
    """
    glob íŒ¨í„´ì—ì„œ ì‚¬ìš©í•  ê²½ë¡œë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.
    ê²½ë¡œ êµ¬ë¶„ìë¥¼ í†µì¼í•˜ê³  íŠ¹ìˆ˜ ë¬¸ìê°€ ìˆëŠ” ë¶€ë¶„ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    # ê²½ë¡œ êµ¬ë¶„ì í†µì¼ (ë°±ìŠ¬ë˜ì‹œ -> ìŠ¬ë˜ì‹œ)
    normalized_path = path.replace("\\", "/")

    # ì™€ì¼ë“œì¹´ë“œ ìˆëŠ”ì§€ í™•ì¸
    has_wildcard = "*" in normalized_path or "?" in normalized_path

    if has_wildcard:
        # ê²½ë¡œì™€ íŒ¨í„´ ë¶€ë¶„ ë¶„ë¦¬
        if "**" in normalized_path:
            # ì¬ê·€ì  íŒ¨í„´ ì²˜ë¦¬
            path_parts = normalized_path.split("/**", 1)
            base_dir = path_parts[0]
            pattern = "/**" + (path_parts[1] if len(path_parts) > 1 else "")
            # base_dir ë¶€ë¶„ë§Œ ì´ìŠ¤ì¼€ì´í”„
            return glob_escape(base_dir) + pattern
        else:
            # ì¼ë°˜ ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´
            last_wildcard_idx = max(
                normalized_path.rfind("*"), normalized_path.rfind("?")
            )
            if last_wildcard_idx != -1:
                last_dir_sep = normalized_path.rfind("/", 0, last_wildcard_idx)
                if last_dir_sep != -1:
                    # ê²½ë¡œì˜ ë””ë ‰í† ë¦¬ ë¶€ë¶„ë§Œ ì´ìŠ¤ì¼€ì´í”„
                    return (
                        glob_escape(normalized_path[:last_dir_sep])
                        + normalized_path[last_dir_sep:]
                    )

    # ì™€ì¼ë“œì¹´ë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ ê²½ë¡œ ì´ìŠ¤ì¼€ì´í”„
    return glob_escape(normalized_path)


def process_modpack_directory(
    modpack_path, translate_config=True, translate_kubejs=True, translate_mods=True
):
    """ëª¨ë“œíŒ© ë””ë ‰í† ë¦¬ì—ì„œ ë²ˆì—­ ëŒ€ìƒ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    supported_extensions = get_supported_extensions()

    # ë²ˆì—­ ëŒ€ìƒ íŒŒì¼ ê²€ìƒ‰
    en_us_files = []

    # config í´ë” ë‚´ íŒŒì¼ ê²€ìƒ‰ (ì„ íƒí•œ ê²½ìš°)
    if translate_config:
        config_glob_path = normalize_glob_path(
            os.path.join(modpack_path, "config/**/*.*")
        )
        config_files = glob(config_glob_path, recursive=True)
        for f in config_files:
            f = f.replace("\\", "/")
            file_ext = os.path.splitext(f)[1]
            if file_ext in supported_extensions and any(
                whitelist_dir in f for whitelist_dir in DIR_FILTER_WHITELIST
            ):
                en_us_files.append(f)
            elif file_ext in supported_extensions and ("en_us" in f or "en_US" in f):
                en_us_files.append(f)

    # kubejs í´ë” ë‚´ íŒŒì¼ ê²€ìƒ‰ (ì„ íƒí•œ ê²½ìš°)
    if translate_kubejs:
        kubejs_glob_path = normalize_glob_path(
            os.path.join(modpack_path, "kubejs/**/*.*")
        )
        kubejs_files = glob(kubejs_glob_path, recursive=True)
        for f in kubejs_files:
            f = f.replace("\\", "/")
            file_ext = os.path.splitext(f)[1]
            if file_ext in supported_extensions and any(
                whitelist_dir in f for whitelist_dir in DIR_FILTER_WHITELIST
            ):
                en_us_files.append(f)
            elif file_ext in supported_extensions and ("en_us" in f or "en_US" in f):
                en_us_files.append(f)

    # mods í´ë” ë‚´ jar íŒŒì¼ ê²€ìƒ‰ (ì„ íƒí•œ ê²½ìš°)
    mods_jar_files = []
    if translate_mods:
        mods_glob_path = normalize_glob_path(os.path.join(modpack_path, "mods/*.jar"))
        mods_jar_files = glob(mods_glob_path)

        extract_dir = os.path.join(modpack_path, "extracted")
        os.makedirs(extract_dir, exist_ok=True)

        for jar_path in mods_jar_files:
            try:
                with zipfile.ZipFile(jar_path, "r") as jar:
                    # ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ ì°¾ê¸°
                    lang_files = [
                        f
                        for f in jar.namelist()
                        if os.path.splitext(f)[1] in supported_extensions
                        and (
                            any(
                                whitelist_dir in f
                                for whitelist_dir in DIR_FILTER_WHITELIST
                            )
                            or ("en_us" in f.lower() or "en_US" in f.lower())
                        )
                    ]

                    for lang_file in lang_files:
                        # ì„ì‹œ ë””ë ‰í† ë¦¬ì— íŒŒì¼ ì¶”ì¶œ
                        extract_path = os.path.join(
                            extract_dir, os.path.basename(jar_path), lang_file
                        ).replace("\\", "/")
                        os.makedirs(os.path.dirname(extract_path), exist_ok=True)

                        with (
                            jar.open(lang_file) as source,
                            open(extract_path, "wb") as target,
                        ):
                            shutil.copyfileobj(source, target)

                        en_us_files.append(extract_path)
            except Exception as e:
                st.error(
                    f"JAR íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}, {jar_path}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
                )
                error_traceback = traceback.format_exc()
                logger.error(error_traceback)

    return en_us_files, mods_jar_files


def extract_lang_content(file_path):
    """íŒŒì¼ì—ì„œ ì–¸ì–´ ë‚´ìš©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        file_ext = os.path.splitext(file_path)[1]
        parser_class = get_parser_by_extension(file_ext)

        if parser_class:
            return parser_class.load(content)
        else:
            st.error(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
            return {}
    except Exception as e:
        st.error(
            f"íŒŒì¼ ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {file_path}, {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
        )
        error_traceback = traceback.format_exc()
        logger.error(error_traceback)
        return {}


def save_lang_content(file_path, data):
    """ì–¸ì–´ ë‚´ìš©ì„ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        file_ext = os.path.splitext(file_path)[1]
        parser_class = get_parser_by_extension(file_ext)

        if parser_class:
            content = parser_class.save(data)

            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)

            return True
        else:
            st.error(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
            return False
    except Exception as e:
        st.error(
            f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
        )
        error_traceback = traceback.format_exc()
        logger.error(error_traceback)
        return False


def main():
    st.title("ë§ˆì¸í¬ë˜í”„íŠ¸ ëª¨ë“œíŒ© ìë™ ë²ˆì—­ê¸°")

    # ê¸€ë¡œë²Œ API í‚¤ ì¸ë±ìŠ¤ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
    if "api_key_index" not in st.session_state:
        st.session_state.api_key_index = 0

    # ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ì„ íƒ ì˜µì…˜
    st.sidebar.header("ë²ˆì—­ ì„¤ì •")

    # LLM ëª¨ë¸ ì„ íƒ
    model_provider = st.sidebar.selectbox(
        "AI ëª¨ë¸ ì œê³µì ì„ íƒ", ["OpenAI", "Google", "Grok", "Ollama", "Anthropic"]
    )

    # ëª¨ë¸ ì œê³µìì— ë”°ë¥¸ í‚¤ì™€ ëª¨ë¸ ì…ë ¥ í•„ë“œ
    env_api_key = os.getenv(API_KEY_ENV_VARS.get(model_provider, ""))

    # API í‚¤ ì €ì¥ì†Œ í‚¤
    api_keys_key = f"{model_provider}_api_keys"

    # API í‚¤ ê´€ë¦¬ ì„¹ì…˜
    st.sidebar.subheader("API í‚¤ ê´€ë¦¬")

    # ì„¸ì…˜ ìƒíƒœì— API í‚¤ ì €ì¥
    if api_keys_key not in st.session_state:
        st.session_state[api_keys_key] = env_api_key if env_api_key else ""

    # API í‚¤ í…ìŠ¤íŠ¸ ì˜ì—­ (ì—¬ëŸ¬ ì¤„ ì…ë ¥ ê°€ëŠ¥)
    api_keys_text = st.sidebar.text_area(
        f"{model_provider} API í‚¤ ëª©ë¡ (í•œ ì¤„ì— í•˜ë‚˜ì”©)",
        value=st.session_state[api_keys_key],
        placeholder="ì—¬ëŸ¬ API í‚¤ë¥¼ í•œ ì¤„ì— í•˜ë‚˜ì”© ì…ë ¥í•˜ì„¸ìš”.\në²ˆì—­ ì‹œ ìœ„ì—ì„œë¶€í„° ìˆœì„œëŒ€ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.",
        height=150,
        key=f"{model_provider}_api_keys_input",
    )

    # ì…ë ¥ëœ API í‚¤ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state[api_keys_key] = api_keys_text

    # API í‚¤ ëª©ë¡ ì²˜ë¦¬
    api_keys = [key.strip() for key in api_keys_text.split("\n") if key.strip()]

    # API í‚¤ ê°€ì ¸ì˜¤ê¸°/ë‚´ë³´ë‚´ê¸° ë²„íŠ¼
    api_keys_col1, api_keys_col2 = st.sidebar.columns(2)

    with api_keys_col1:
        if st.button("API í‚¤ ë‚´ë³´ë‚´ê¸°", key=f"{model_provider}_export_button"):
            if api_keys:
                # API í‚¤ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
                api_keys_json = json.dumps(
                    {model_provider: api_keys}, ensure_ascii=False, indent=2
                )
                # ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
                st.download_button(
                    label="JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=api_keys_json,
                    file_name=f"{model_provider.lower()}_api_keys.json",
                    mime="application/json",
                    key=f"{model_provider}_download_button",
                )
            else:
                st.sidebar.warning("ë‚´ë³´ë‚¼ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with api_keys_col2:
        api_keys_file = st.file_uploader(
            "API í‚¤ ê°€ì ¸ì˜¤ê¸°", type=["json"], key=f"{model_provider}_import_file"
        )
        if api_keys_file is not None:
            try:
                api_keys_data = json.load(api_keys_file)
                if model_provider in api_keys_data and isinstance(
                    api_keys_data[model_provider], list
                ):
                    # ê¸°ì¡´ í…ìŠ¤íŠ¸ ì˜ì—­ ê°’ì„ ìƒˆë¡œìš´ API í‚¤ë¡œ ì—…ë°ì´íŠ¸
                    st.session_state[api_keys_key] = "\n".join(
                        api_keys_data[model_provider]
                    )
                    st.sidebar.success(
                        f"{len(api_keys_data[model_provider])}ê°œì˜ API í‚¤ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤."
                    )
                    st.experimental_rerun()
                else:
                    st.sidebar.warning(
                        f"JSON íŒŒì¼ì— {model_provider} API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤."
                    )
            except Exception as e:
                st.sidebar.error(f"JSON íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

    model_options = {
        "OpenAI": [
            "gpt-4.5-preview",
            "gpt-4o",
            "gpt-4o-mini",
        ],
        "Google": [
            "gemini-2.0-flash",
            "gemini-2.0-flash-lite",
        ],
        "Grok": ["grok-2-1212"],
        "Ollama": ["ì§ì ‘ ì…ë ¥ í•˜ì„¸ìš”."],
        "Anthropic": [
            "claude-3-7-sonnet-20250219",
            "claude-3-5-sonnet-20241022",
        ],
    }

    # ëª¨ë¸ ì„ íƒ (ë“œë¡­ë‹¤ìš´ ë˜ëŠ” ì§ì ‘ ì…ë ¥)
    use_custom_model = st.sidebar.checkbox("ì§ì ‘ ëª¨ë¸ëª… ì…ë ¥í•˜ê¸°")

    if use_custom_model:
        selected_model = st.sidebar.text_input("ëª¨ë¸ëª… ì§ì ‘ ì…ë ¥")
    else:
        selected_model = st.sidebar.selectbox(
            "ëª¨ë¸ ì„ íƒ", model_options.get(model_provider, [])
        )

    # API Base URL (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¨¼ì € ì½ê¸°)
    env_api_base = os.getenv(API_BASE_ENV_VARS.get(model_provider, ""))
    default_api_base = "http://localhost:11434" if model_provider == "Ollama" else ""

    # API Base URL ìˆ˜ì • ì—¬ë¶€ ì²´í¬ë°•ìŠ¤
    use_custom_api_base = st.sidebar.checkbox("API Base URL ìˆ˜ì •í•˜ê¸°")

    if use_custom_api_base:
        api_base_url = st.sidebar.text_input(
            "API Base URL", value=env_api_base if env_api_base else default_api_base
        )
    else:
        api_base_url = None

    # ëª¨ë¸ ì˜¨ë„(temperature) ì„¤ì • - ëª¨ë“  ëª¨ë¸ì— ê³µí†µ ì ìš©
    temperature = st.sidebar.slider(
        "Temperature",
        min_value=0.0,
        max_value=1.0,
        value=0.1,
        step=0.05,
        help="ê°’ì´ ë‚®ì„ìˆ˜ë¡ ë” ì°½ì˜ì„±ì´ ë‚®ì€ ì‘ë‹µì´, ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì„±ì´ ë†’ì€ ì‘ë‹µì´ ìƒì„±ë©ë‹ˆë‹¤.",
    )

    # API ì†ë„ ì œí•œ ì„¤ì •
    st.sidebar.subheader("API ì†ë„ ì œí•œ")
    use_rate_limiter = st.sidebar.checkbox("API ì†ë„ ì œí•œ ì‚¬ìš©", value=True)
    rpm = st.sidebar.number_input(
        "ë¶„ë‹¹ ìš”ì²­ ìˆ˜(RPM)",
        min_value=1,
        max_value=1000,
        value=60,
        step=1,
        disabled=not use_rate_limiter,
        help="ë¶„ë‹¹ ìµœëŒ€ API ìš”ì²­ íšŸìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ê°’ì´ ë‚®ì„ìˆ˜ë¡ API í• ë‹¹ëŸ‰ì„ ì ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

    # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
    st.sidebar.subheader("ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •")
    max_workers = st.sidebar.number_input(
        "ë™ì‹œ ì‘ì—… ìˆ˜",
        min_value=1,
        max_value=20,
        value=5,
        step=1,
        help="ë™ì‹œì— ì²˜ë¦¬í•  ë²ˆì—­ ì‘ì—… ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ê°’ì´ ë†’ì„ìˆ˜ë¡ ë²ˆì—­ ì†ë„ê°€ ë¹¨ë¼ì§€ì§€ë§Œ, API í• ë‹¹ëŸ‰ì„ ë¹ ë¥´ê²Œ ì†Œëª¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

    # ì»¤ìŠ¤í…€ ì‚¬ì „ ì—…ë¡œë“œ
    st.sidebar.header("ì»¤ìŠ¤í…€ ì‚¬ì „")
    custom_dict_file = st.sidebar.file_uploader(
        "ì»¤ìŠ¤í…€ ì‚¬ì „ ì—…ë¡œë“œ (JSON)", type=["json"]
    )

    # ëª¨ë“œíŒ© ì„ íƒ
    st.header("ëª¨ë“œíŒ© íŒŒì¼ ì„ íƒ")

    # í´ë” ì„ íƒ (ì‹¤ì œë¡œëŠ” í´ë” ê²½ë¡œ ì…ë ¥)
    modpack_path = st.text_input(
        "ëª¨ë“œíŒ© í´ë” ê²½ë¡œ",
        "",
        placeholder="í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: C:\\Users\\<<ì´ë¦„>>\\Documents\\Minecraft\\mods\\my_modpack)",
    ).replace("\\", "/")

    # ë²ˆì—­ ê²°ê³¼, ê¸°ì¡´ ë²ˆì—­ ìë™ ì‚¬ì „ êµ¬ì¶• ì˜µì…˜
    build_dict_from_existing = st.checkbox("ê¸°ì¡´ ë²ˆì—­ì—ì„œ ì‚¬ì „ ìë™ êµ¬ì¶•", value=True)

    # ë²ˆì—­ ê²°ê³¼ ì¶œë ¥ ê²½ë¡œ
    output_path = st.text_input(
        "ë²ˆì—­ ê²°ê³¼ ì¶œë ¥ ê²½ë¡œ",
        "",
        placeholder="ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: C:\\Users\\<<ì´ë¦„>>\\Documents\\Minecraft\\mods\\my_modpack\\output)",
    ).replace("\\", "/")

    # ì˜µì…˜: ì´ë¯¸ ë²ˆì—­ëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
    skip_translated = st.checkbox("ì´ë¯¸ ë²ˆì—­ëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°", value=True)

    # ë¦¬ì†ŒìŠ¤íŒ© ì´ë¦„ ì„¤ì •
    resourcepack_name = st.text_input("ë¦¬ì†ŒìŠ¤íŒ© ì´ë¦„", "Auto-Translated-KO")

    output_path = os.path.join(output_path, resourcepack_name)

    # ë²ˆì—­ ì¹´í…Œê³ ë¦¬ ì„ íƒ
    st.subheader("ë²ˆì—­ ì¹´í…Œê³ ë¦¬ ì„ íƒ")
    translate_config = st.checkbox("Config íŒŒì¼ ë²ˆì—­", value=True)
    translate_kubejs = st.checkbox("KubeJS íŒŒì¼ ë²ˆì—­", value=True)
    translate_mods = st.checkbox("Mods íŒŒì¼ ë²ˆì—­", value=True)

    # ì»¤ìŠ¤í…€ ì‚¬ì „ ì²˜ë¦¬
    translation_dictionary = {}
    translation_dictionary_lowercase = {}

    # ê³µì‹ ë§ˆì¸í¬ë˜í”„íŠ¸ ë²ˆì—­ íŒŒì¼ì—ì„œ ì‚¬ì „ êµ¬ì¶•
    try:
        # ì˜ì–´-í•œêµ­ì–´ ë§¤í•‘ ìƒì„±
        for key, en_value in OFFICIAL_EN_LANG_FILE.items():
            if key in OFFICIAL_KO_LANG_FILE:
                ko_value = OFFICIAL_KO_LANG_FILE[key]
                if en_value and ko_value:  # ë¹ˆ ê°’ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€
                    add_to_dictionary(
                        en_value,
                        ko_value,
                        translation_dictionary,
                        translation_dictionary_lowercase,
                    )

        st.sidebar.success(
            f"ê³µì‹ ë§ˆì¸í¬ë˜í”„íŠ¸ ë²ˆì—­ ì‚¬ì „ ë¡œë“œ ì™„ë£Œ: {len(translation_dictionary)}ê°œ í•­ëª©"
        )
    except Exception as e:
        st.sidebar.warning(f"ê³µì‹ ë²ˆì—­ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        logger.warning(f"ê³µì‹ ë²ˆì—­ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

    if custom_dict_file is not None:
        try:
            translation_dictionary = json.load(custom_dict_file)
            translation_dictionary_lowercase = {
                k.lower(): k for k, v in translation_dictionary.items()
            }
            st.sidebar.success(
                f"ì»¤ìŠ¤í…€ ì‚¬ì „ ë¡œë“œ ì™„ë£Œ: {len(translation_dictionary)}ê°œ í•­ëª©"
            )
        except Exception as e:
            st.sidebar.error(
                f"ì‚¬ì „ ë¡œë“œ ì˜¤ë¥˜: {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
            error_traceback = traceback.format_exc()
            logger.error(error_traceback)

    # ë²ˆì—­ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ë²ˆì—­ ì‹œì‘"):
        if not api_keys:
            st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        if not os.path.exists(modpack_path):
            st.error("ëª¨ë“œíŒ© í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        # ìµœì†Œí•œ í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬ëŠ” ì„ íƒë˜ì–´ì•¼ í•¨
        if not (translate_config or translate_kubejs or translate_mods):
            st.error("ìµœì†Œí•œ í•˜ë‚˜ì˜ ë²ˆì—­ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return

        # ë²ˆì—­ ì‹œì‘
        try:
            with st.spinner("ë²ˆì—­ ì§„í–‰ ì¤‘..."):
                # ì „ì²´ ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ìƒíƒœ í‘œì‹œ ë°”ì™€ ì •ë³´ í‘œì‹œ ì˜ì—­
                st.subheader("ì „ì²´ ì§„í–‰ ìƒí™©")
                progress_cols = st.columns([4, 1])
                with progress_cols[0]:
                    overall_progress_bar = st.progress(0)
                with progress_cols[1]:
                    overall_progress_text = st.empty()
                status_text = st.empty()

                # ë¡œê·¸ ì˜ì—­ ì„¤ì •
                log_container = st.expander("ë²ˆì—­ ë¡œê·¸", expanded=True)
                logs = []  # ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

                # ë¡œê·¸ ì¶œë ¥ í•¨ìˆ˜
                def add_log(message, level="info"):
                    logs.append(
                        {
                            "message": message,
                            "level": level,
                            "time": uuid.uuid4().hex[:8],
                        }
                    )
                    with log_container:
                        # ê°€ì¥ ìµœê·¼ ë¡œê·¸ 20ê°œë§Œ í‘œì‹œ
                        for log in logs[-20:]:
                            if log["level"] == "info":
                                st.info(f"[{log['time']}] {log['message']}")
                            elif log["level"] == "warning":
                                st.warning(f"[{log['time']}] {log['message']}")
                            elif log["level"] == "error":
                                st.error(f"[{log['time']}] {log['message']}")
                            elif log["level"] == "success":
                                st.success(f"[{log['time']}] {log['message']}")

                # ì‘ì—…ìë³„ ì§„í–‰ ìƒí™© ì»¨í…Œì´ë„ˆ
                worker_progress_bars = {}
                worker_progress_texts = {}
                worker_status_texts = {}

                # ì‘ì—…ìë³„ ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
                for i in range(max_workers):
                    st.markdown(f"### Worker {i + 1}")
                    worker_cols = st.columns([3, 1])

                    with worker_cols[0]:
                        worker_progress_bars[i] = st.progress(0)
                    with worker_cols[1]:
                        worker_progress_texts[i] = st.empty()

                    worker_status_texts[i] = st.empty()
                    st.markdown("---")

                # LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                status_text.text("ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
                add_log("ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")

                # ê¸€ë¡œë²Œ API í‚¤ ì¸ë±ìŠ¤ ì´ˆê¸°í™”
                st.session_state.api_key_index = 0
                total_api_keys = len(api_keys)

                add_log(f"ì´ {total_api_keys}ê°œì˜ API í‚¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

                try:
                    # Rate Limiter ì„¤ì •
                    rate_limiter = None
                    if use_rate_limiter:
                        # RPMì„ RPS(ì´ˆë‹¹ ìš”ì²­ ìˆ˜)ë¡œ ë³€í™˜
                        rps = rpm / 60.0
                        rate_limiter = InMemoryRateLimiter(
                            requests_per_second=rps,
                            check_every_n_seconds=0.1,
                            max_bucket_size=10,
                        )
                        status_text.text(f"ì†ë„ ì œí•œ: {rpm} RPM ({rps:.2f} RPS)")
                        add_log(f"ì†ë„ ì œí•œ ì„¤ì •: {rpm} RPM ({rps:.2f} RPS)")

                    # í˜„ì¬ API í‚¤ ê°€ì ¸ì˜¤ê¸°
                    st.session_state.api_key_index = (
                        st.session_state.api_key_index + 1
                    ) % total_api_keys

                    add_log(
                        f"API í‚¤ ì‚¬ìš© ì¤‘: {st.session_state.api_key_index}/{total_api_keys}"
                    )

                except RuntimeError as e:
                    add_log(f"ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", "error")
                    st.error(
                        f"ëª¨ë¸ ì´ˆê¸°í™” ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜ ë©”ì‹œì§€: {e}"
                    )
                    return

                # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
                os.makedirs(output_path, exist_ok=True)
                dictionary_path = os.path.join(output_path, "dictionary")
                os.makedirs(dictionary_path, exist_ok=True)
                add_log(f"ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {output_path}")

                # UUID ìƒì„± (ë¦¬ì†ŒìŠ¤íŒ© ì‹ë³„ìë¡œ ì‚¬ìš©)
                uuid_str = str(uuid.uuid4())

                # ëª¨ë“œíŒ© ë””ë ‰í† ë¦¬ì—ì„œ ë²ˆì—­í•  íŒŒì¼ ì°¾ê¸°
                status_text.text("ë²ˆì—­ ëŒ€ìƒ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
                add_log("ë²ˆì—­ ëŒ€ìƒ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
                en_us_files, mods_jar_files = process_modpack_directory(
                    modpack_path, translate_config, translate_kubejs, translate_mods
                )

                if len(en_us_files) == 0:
                    add_log("ë²ˆì—­í•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "warning")
                    st.warning("ë²ˆì—­í•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return

                status_text.text(f"{len(en_us_files)}ê°œì˜ ì–¸ì–´ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                add_log(f"{len(en_us_files)}ê°œì˜ ì–¸ì–´ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

                # ê¸°ì¡´ ë²ˆì—­ì—ì„œ ì‚¬ì „ êµ¬ì¶•
                if build_dict_from_existing:
                    status_text.text("ê¸°ì¡´ ë²ˆì—­ì—ì„œ ì‚¬ì „ êµ¬ì¶• ì¤‘...")
                    add_log("ê¸°ì¡´ ë²ˆì—­ì—ì„œ ì‚¬ì „ êµ¬ì¶• ì¤‘...")

                    # JAR íŒŒì¼ì—ì„œ ì‚¬ì „ êµ¬ì¶•
                    (
                        translation_dictionary,
                        translation_dictionary_lowercase,
                        jar_files_count,
                        jar_entries_added,
                    ) = build_dictionary_from_jar(
                        mods_jar_files,
                        translation_dictionary,
                        translation_dictionary_lowercase,
                    )
                    add_log(
                        f"JAR íŒŒì¼ {jar_files_count}ê°œì—ì„œ {jar_entries_added}ê°œ í•­ëª© ì¶”ê°€"
                    )

                    # ì¼ë°˜ íŒŒì¼ì—ì„œ ì‚¬ì „ êµ¬ì¶•
                    (
                        translation_dictionary,
                        translation_dictionary_lowercase,
                        files_count,
                        entries_added,
                    ) = build_dictionary_from_files(
                        en_us_files,
                        modpack_path,
                        translation_dictionary,
                        translation_dictionary_lowercase,
                    )
                    add_log(
                        f"ì¼ë°˜ íŒŒì¼ {files_count}ê°œì—ì„œ {entries_added}ê°œ í•­ëª© ì¶”ê°€"
                    )

                    # ì‚¬ì „ ì •ë³´ í‘œì‹œ
                    total_files = jar_files_count + files_count
                    total_entries = jar_entries_added + entries_added
                    add_log(
                        f"ì´ {total_files}ê°œ íŒŒì¼ì—ì„œ {total_entries}ê°œ í•­ëª©ì„ ì‚¬ì „ì— ì¶”ê°€",
                        "success",
                    )

                    with log_container:
                        st.info(
                            f"ê¸°ì¡´ ë²ˆì—­ì—ì„œ {total_files}ê°œ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ {total_entries}ê°œ í•­ëª©ì„ ì‚¬ì „ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤."
                        )

                status_text.text(
                    f"ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤... ({len(translation_dictionary)}ê°œ ì‚¬ì „ í•­ëª© ì‚¬ìš©)"
                )
                add_log(
                    f"ë²ˆì—­ ì‹œì‘ ({len(translation_dictionary)}ê°œ ì‚¬ì „ í•­ëª© ì‚¬ìš©)",
                    "success",
                )

                # ë²ˆì—­ íŒŒì¼ ë§¤í•‘ (ì›ë³¸ -> ë²ˆì—­)
                translated_files = {}

                # ì˜¤ë¥˜ ë°œìƒ íŒŒì¼ ëª©ë¡
                failed_files = []

                # íŒŒì¼ íƒ€ì…ë³„ ë¶„ë¥˜
                file_types = {"config": [], "kubejs": [], "mods": []}

                for file_path in en_us_files:
                    # tmp_ ë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                    if os.path.basename(file_path).startswith("tmp_"):
                        continue

                    if "/config/" in file_path or "\\config\\" in file_path:
                        file_types["config"].append(file_path)
                    elif "/kubejs/" in file_path or "\\kubejs\\" in file_path:
                        file_types["kubejs"].append(file_path)
                    else:
                        file_types["mods"].append(file_path)

                # ì„ íƒë˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                if not translate_config:
                    file_types["config"] = []
                if not translate_kubejs:
                    file_types["kubejs"] = []
                if not translate_mods:
                    file_types["mods"] = []

                # íŒŒì¼ íƒ€ì…ë³„ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
                with open(
                    os.path.join(output_path, "processing_info.json"),
                    "w",
                    encoding="utf-8",
                ) as f:
                    json.dump(file_types, f, ensure_ascii=False, indent=4)

                # ì¹´í…Œê³ ë¦¬ë³„ ë²ˆì—­ ì§„í–‰
                total_files = len(en_us_files)
                processed_files = 0

                # ì‘ì—…ìë³„ ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
                worker_statuses = {
                    i: {"active": False, "file": "", "progress": 0}
                    for i in range(max_workers)
                }

                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜
                async def update_progress(
                    worker_id,
                    file_path=None,
                    progress=None,
                    done=False,
                    total_items=None,
                    processed_items=None,
                ):
                    if file_path:
                        worker_statuses[worker_id]["file"] = os.path.basename(file_path)

                    if progress is not None:
                        worker_statuses[worker_id]["progress"] = progress

                    if done:
                        worker_statuses[worker_id]["active"] = False
                        nonlocal processed_files
                        processed_files += 1
                        overall_progress = int((processed_files / total_files) * 100)
                        overall_progress_bar.progress(overall_progress)
                        overall_progress_text.markdown(
                            f"**{processed_files}/{total_files}** ({overall_progress}%)"
                        )
                    else:
                        worker_statuses[worker_id]["active"] = True

                    # ì‘ì—…ì ìƒíƒœ ì—…ë°ì´íŠ¸
                    status_prefix = (
                        "ğŸŸ¢ Active"
                        if worker_statuses[worker_id]["active"]
                        else "âšª Waiting"
                    )

                    if total_items and processed_items is not None:
                        item_progress = f"{processed_items}/{total_items} í•­ëª©"
                        worker_status_texts[worker_id].markdown(
                            f"{status_prefix} - **{worker_statuses[worker_id]['file']}** ({item_progress})"
                        )
                    else:
                        worker_status_texts[worker_id].markdown(
                            f"{status_prefix} - **{worker_statuses[worker_id]['file']}**"
                        )

                    worker_progress_bars[worker_id].progress(
                        worker_statuses[worker_id]["progress"]
                    )
                    worker_progress_texts[worker_id].markdown(
                        f"**{worker_statuses[worker_id]['progress']}%**"
                    )

                    # ì „ì²´ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                    percent_complete = int((processed_files / total_files) * 100)
                    status_text.markdown(
                        f"ë²ˆì—­ ì¤‘... **{processed_files}/{total_files}** íŒŒì¼ ì™„ë£Œ ({percent_complete}%) - "
                        f"í™œì„± ì‘ì—…ì: {sum(1 for s in worker_statuses.values() if s['active'])}ëª…"
                    )

                # ì‚¬ì „ ì •ë ¬ ë° í•„í„°ë§ í•¨ìˆ˜
                def sort_and_filter_dictionary():
                    sorted_dict = {}
                    for k, v in sorted(
                        translation_dictionary.items(),
                        key=lambda item: len(item[0]),
                        reverse=True,
                    ):
                        if (
                            len(k.split(" ")) <= 10
                            and not re.search(r"[.?!%]", k)
                            and not re.search(
                                r"[.?!%]", ", ".join(v) if isinstance(v, list) else v
                            )
                        ):
                            if isinstance(v, list):
                                sorted_dict[k] = v
                            else:
                                sorted_dict[k] = v
                    return sorted_dict

                # ê° ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„±
                for category in ["config", "kubejs", "mods"]:
                    os.makedirs(
                        os.path.join(output_path, category, "input"), exist_ok=True
                    )
                    os.makedirs(
                        os.path.join(output_path, category, "output"), exist_ok=True
                    )

                # ë‹¨ì¼ íŒŒì¼ ë²ˆì—­ í•¨ìˆ˜
                async def translate_file(worker_id, en_file, category):
                    try:
                        # ì‘ì—…ì ìƒíƒœ ì—…ë°ì´íŠ¸
                        await update_progress(worker_id, en_file, 0)

                        # í˜„ì¬ API í‚¤ ê°€ì ¸ì˜¤ê¸°
                        current_api_key = api_keys[
                            st.session_state.api_key_index % total_api_keys
                        ]

                        # ë‹¤ìŒ API í‚¤ ì¸ë±ìŠ¤ë¡œ ì—…ë°ì´íŠ¸
                        st.session_state.api_key_index = (
                            st.session_state.api_key_index + 1
                        ) % total_api_keys

                        # íŒŒì¼ ì´ë¦„ì´ tmp_ë¡œ ì‹œì‘í•˜ë©´ ê±´ë„ˆë›°ê¸°
                        if os.path.basename(en_file).startswith("tmp_"):
                            await update_progress(worker_id, en_file, 100, True)
                            return

                        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •
                        rel_path = en_file.replace(modpack_path, "").lstrip("/\\")

                        # ì¹´í…Œê³ ë¦¬ë³„ ì¶œë ¥ ê²½ë¡œ ì„¤ì •
                        input_file = os.path.join(
                            output_path,
                            category,
                            "input",
                            rel_path.replace("en_us", LANG_CODE).replace(
                                "en_US", LANG_CODE
                            ),
                        )

                        output_file = os.path.join(
                            output_path,
                            category,
                            "output",
                            rel_path.replace("en_us", LANG_CODE).replace(
                                "en_US", LANG_CODE
                            ),
                        )

                        # ì´ë¯¸ ë²ˆì—­ëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
                        if skip_translated and os.path.exists(output_file):
                            await update_progress(worker_id, en_file, 100, True)
                            translated_files[en_file] = output_file
                            return

                        try:
                            # ì…ë ¥ íŒŒì¼ ë‚´ìš© ì¶”ì¶œ
                            en_data = extract_lang_content(en_file)
                            if not en_data:
                                await update_progress(worker_id, en_file, 100, True)
                                return

                            # ë°ì´í„°ê°€ ì‚¬ì „ì´ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
                            if not isinstance(en_data, dict):
                                await update_progress(worker_id, en_file, 100, True)
                                return

                            # ì…ë ¥ ë””ë ‰í† ë¦¬ ìƒì„± ë° íŒŒì¼ ì €ì¥
                            input_dir = os.path.dirname(input_file)
                            os.makedirs(input_dir, exist_ok=True)

                            with open(input_file, "w", encoding="utf-8") as f:
                                json.dump(en_data, f, ensure_ascii=False, indent=4)

                            # ë²ˆì—­ ì²˜ë¦¬
                            nonlocal translation_dictionary
                            nonlocal translation_dictionary_lowercase
                            translation_dictionary = sort_and_filter_dictionary()

                            # ì„ì‹œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
                            temp_output_path = output_file + ".tmp"

                            # ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ ë°˜ë“œì‹œ ìƒì„±
                            output_dir = os.path.dirname(output_file)
                            os.makedirs(output_dir, exist_ok=True)

                            # ë²ˆì—­ íŒŒì¼ì˜ ì´ í•­ëª© ìˆ˜
                            total_items = len(en_data)
                            processed_items = 0

                            # ë²ˆì—­ í•¨ìˆ˜ ì •ì˜
                            async def progress_callback():
                                # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ í•­ëª© ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                                nonlocal en_data
                                nonlocal processed_items
                                items_count = len(en_data)
                                if items_count > 0:
                                    # ì²˜ë¦¬ëœ í•­ëª© ìˆ˜ ì¦ê°€ (ì¶”ì •ì¹˜)
                                    processed_items = min(
                                        processed_items
                                        + max(1, int(items_count * 0.05)),
                                        items_count - 1,
                                    )

                                    # ì§„í–‰ë¥  ê³„ì‚°
                                    progress_percent = int(
                                        (processed_items / items_count) * 100
                                    )

                                    # ì‘ì—…ìì˜ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (ìµœëŒ€ 95%ê¹Œì§€)
                                    new_progress = min(progress_percent, 95)
                                    await update_progress(
                                        worker_id,
                                        None,
                                        new_progress,
                                        False,
                                        total_items,
                                        processed_items,
                                    )

                            # ë²ˆì—­ ì‹¤í–‰
                            try:
                                translation_dictionary = await minecraft_modpack_auto_translator.translate_json_file(
                                    input_path=input_file,
                                    output_path=temp_output_path,  # ì„ì‹œ íŒŒì¼ì— JSONìœ¼ë¡œ ì €ì¥
                                    custom_dictionary_dict=translation_dictionary,
                                    llm=get_translator(
                                        provider=model_provider.lower(),
                                        api_key=current_api_key,
                                        model_name=selected_model,
                                        api_base=api_base_url,
                                        temperature=temperature,
                                        rate_limiter=rate_limiter,
                                    ),
                                    max_workers=1,  # ë‹¨ì¼ íŒŒì¼ ë‚´ì—ì„œëŠ” ë³‘ë ¬ ì²˜ë¦¬ ì•ˆí•¨
                                    progress_callback=progress_callback,
                                )

                                # ëª¨ë“  í•­ëª© ì²˜ë¦¬ ì™„ë£Œ
                                processed_items = total_items
                                await update_progress(
                                    worker_id,
                                    None,
                                    95,
                                    False,
                                    total_items,
                                    processed_items,
                                )

                                # ì›ë˜ íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                if os.path.exists(temp_output_path):
                                    file_ext = os.path.splitext(en_file)[1]
                                    parser_class = get_parser_by_extension(file_ext)

                                    if parser_class:
                                        # ì„ì‹œ JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
                                        with open(
                                            temp_output_path, "r", encoding="utf-8"
                                        ) as f:
                                            data = json.load(f)

                                        # ì›ë³¸ íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                        content = parser_class.save(data)

                                        # ìµœì¢… íŒŒì¼ ì €ì¥
                                        with open(
                                            output_file, "w", encoding="utf-8"
                                        ) as f:
                                            f.write(content)

                                        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                                        try:
                                            os.remove(temp_output_path)
                                        except OSError:
                                            logger.warning(
                                                f"ì„ì‹œ íŒŒì¼ì„ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {temp_output_path}"
                                            )

                                        # ì‘ì—… ì™„ë£Œ í‘œì‹œ
                                        await update_progress(
                                            worker_id,
                                            None,
                                            100,
                                            True,
                                            total_items,
                                            total_items,
                                        )
                                    else:
                                        logger.warning(
                                            f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}"
                                        )
                                        await update_progress(
                                            worker_id, None, 100, True
                                        )
                                else:
                                    logger.warning(
                                        f"ë²ˆì—­ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {temp_output_path}"
                                    )
                                    await update_progress(worker_id, None, 100, True)
                            except Exception as e:
                                logger.error(
                                    f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
                                )
                                logger.error(traceback.format_exc())

                                # ì˜¤ë¥˜ íŒŒì¼ ê¸°ë¡
                                failed_file_info = {
                                    "path": en_file,
                                    "error": str(e),
                                    "category": category,
                                }
                                failed_files.append(failed_file_info)

                                await update_progress(worker_id, en_file, 100, True)

                        except Exception as e:
                            logger.error(
                                f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
                            )
                            logger.error(traceback.format_exc())

                            # ì˜¤ë¥˜ íŒŒì¼ ê¸°ë¡
                            failed_file_info = {
                                "path": en_file,
                                "error": str(e),
                                "category": category,
                            }
                            failed_files.append(failed_file_info)

                            await update_progress(worker_id, en_file, 100, True)

                    except Exception as e:
                        error_traceback = traceback.format_exc()
                        logger.error(
                            f"íŒŒì¼ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
                        )
                        logger.error(error_traceback)

                        # ì˜¤ë¥˜ íŒŒì¼ ê¸°ë¡
                        failed_file_info = {
                            "path": en_file,
                            "error": str(e),
                            "category": category,
                        }
                        failed_files.append(failed_file_info)

                        await update_progress(worker_id, en_file, 100, True)

                # ë³‘ë ¬ ë²ˆì—­ ì‹¤í–‰ í•¨ìˆ˜
                async def run_translation():
                    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ íŒŒì¼ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©
                    all_files = []
                    for category, files in file_types.items():
                        for f in files:
                            all_files.append((f, category))

                    # ì‘ì—… í ìƒì„±
                    queue = asyncio.Queue()

                    # íì— ëª¨ë“  íŒŒì¼ ì¶”ê°€
                    for file_tuple in all_files:
                        await queue.put(file_tuple)

                    # ì›Œì»¤ í•¨ìˆ˜ ì •ì˜
                    async def worker(worker_id):
                        while not queue.empty():
                            try:
                                file_path, category = await queue.get()
                                await translate_file(worker_id, file_path, category)
                                queue.task_done()
                            except Exception as e:
                                logger.error(f"ì›Œì»¤ {worker_id} ì˜¤ë¥˜: {e}")
                                queue.task_done()

                    # ì›Œì»¤ ì‹œì‘
                    workers = []
                    for i in range(max_workers):
                        task = asyncio.create_task(worker(i))
                        workers.append(task)

                    # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
                    await queue.join()

                    # ì›Œì»¤ íƒœìŠ¤í¬ ì·¨ì†Œ
                    for task in workers:
                        task.cancel()

                    # ì·¨ì†Œëœ íƒœìŠ¤í¬ ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°
                    await asyncio.gather(*workers, return_exceptions=True)

                # ë¹„ë™ê¸° ë²ˆì—­ ì‹¤í–‰
                asyncio.run(run_translation())

                # ë¦¬ì†ŒìŠ¤íŒ© ìƒì„±
                overall_progress_bar.progress(95)
                overall_progress_text.markdown(f"**{total_files}/{total_files}** (95%)")
                status_text.markdown("ë¦¬ì†ŒìŠ¤íŒ© ìƒì„± ì¤‘...")

                # ì¹´í…Œê³ ë¦¬ë³„ ë¦¬ì†ŒìŠ¤íŒ© ì •ë³´
                categories = {
                    "mods": {
                        "name": "Mods",
                        "suffix": "_MOD_TRANSLATION",
                        "emoji": "ğŸŸ¢",
                        "icon": "ğŸ®",
                        "warning": False,
                    },
                    "config": {
                        "name": "Config",
                        "suffix": "_CONFIG_TRANSLATION",
                        "emoji": "ğŸ”·",
                        "icon": "âš™ï¸",
                        "warning": "Config íŒŒì¼ì€ ëª¨ë“œíŒ©ì— ë”°ë¼ ë¦¬ì†ŒìŠ¤íŒ©ìœ¼ë¡œ ì¸ì‹ë˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì••ì¶•ì„ ëª¨ë“œíŒ© Client í´ë”ì— í’€ì–´ì„œ ë®ì–´ì“°ê¸° í•˜ì„¸ìš”.",
                    },
                    "kubejs": {
                        "name": "KubeJS",
                        "suffix": "_KUBEJS_TRANSLATION",
                        "emoji": "ğŸŸ¡",
                        "icon": "ğŸ“œ",
                        "warning": "KubeJS íŒŒì¼ì€ ëª¨ë“œíŒ©ì— ë”°ë¼ ë¦¬ì†ŒìŠ¤íŒ©ìœ¼ë¡œ ì¸ì‹ë˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì••ì¶•ì„ ëª¨ë“œíŒ© Client í´ë”ì— í’€ì–´ì„œ ë®ì–´ì“°ê¸° í•˜ì„¸ìš”.",
                    },
                }

                # ìƒì„±ëœ ë¦¬ì†ŒìŠ¤íŒ©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ì™€ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
                created_resourcepacks = []
                category_packs = {"All": []}

                # ì¹´í…Œê³ ë¦¬ë³„ ë¦¬ì†ŒìŠ¤íŒ© ìƒì„±
                for category, info in categories.items():
                    # ì„ íƒë˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ëŠ” ê±´ë„ˆëœ€
                    if (
                        (category == "config" and not translate_config)
                        or (category == "kubejs" and not translate_kubejs)
                        or (category == "mods" and not translate_mods)
                    ):
                        continue

                    output_dir = os.path.join(output_path, category, "output", "**")
                    output_glob_path = normalize_glob_path(output_dir)
                    if len(glob(output_glob_path, recursive=True)) > 1:
                        # ë¦¬ì†ŒìŠ¤íŒ© ìƒì„±
                        resourcepack_zip = create_resourcepack(
                            output_path,
                            [f"{output_path}/{category}/output"],
                            resourcepack_name + info["suffix"],
                        )

                        # ìƒì„±ëœ ë¦¬ì†ŒìŠ¤íŒ© ì •ë³´ ì €ì¥
                        pack_info = {
                            "category": category,
                            "info": info,
                            "path": resourcepack_zip,
                        }
                        created_resourcepacks.append(pack_info)

                        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ì—ë„ ì¶”ê°€
                        category_name = info["name"]
                        if category_name not in category_packs:
                            category_packs[category_name] = []
                        category_packs[category_name].append(pack_info)
                        category_packs["All"].append(pack_info)

                # ë¦¬ì†ŒìŠ¤íŒ©ì´ ìƒì„±ë˜ì—ˆì„ ê²½ìš°ì—ë§Œ í‘œì‹œ
                if created_resourcepacks:
                    st.header("ğŸ¯ ë²ˆì—­ ê²°ê³¼")

                    # íƒ­ ìƒì„± - ëª¨ë‘ + ê° ì¹´í…Œê³ ë¦¬ë³„
                    tab_titles = ["All"]
                    for pack in created_resourcepacks:
                        cat_name = pack["info"]["name"]
                        if cat_name not in tab_titles:
                            tab_titles.append(cat_name)

                    tabs = st.tabs(tab_titles)

                    # ê° íƒ­ ë‚´ìš© ì±„ìš°ê¸°
                    for i, tab_name in enumerate(tab_titles):
                        with tabs[i]:
                            for pack in category_packs[tab_name]:
                                info = pack["info"]
                                cat_name = info["name"]

                                # í™•ì¥ ê°€ëŠ¥í•œ ì„¹ì…˜ìœ¼ë¡œ í‘œì‹œ
                                with st.expander(
                                    f"{info['icon']} {cat_name} ë¦¬ì†ŒìŠ¤íŒ©", expanded=True
                                ):
                                    # íŒŒì¼ ê²½ë¡œì™€ ë‹¤ìš´ë¡œë“œ ì˜ì—­
                                    st.code(
                                        f"ğŸ“ {pack['path']}",
                                        language=None,
                                    )

                                    # ì‚¬ìš© ë°©ë²• ì•ˆë‚´
                                    st.info(
                                        "ğŸ’¡ **ì‚¬ìš© ë°©ë²•**\n\në§ˆì¸í¬ë˜í”„íŠ¸ ì„¤ì •ì—ì„œ ë¦¬ì†ŒìŠ¤íŒ© íƒ­ì„ ì„ íƒí•˜ì—¬ ì´ ë¦¬ì†ŒìŠ¤íŒ©ì„ ì ìš©í•˜ì„¸ìš”."
                                    )

                                    # ê²½ê³  ë©”ì‹œì§€ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
                                    if info["warning"]:
                                        st.warning(
                                            f"âš ï¸ **ì£¼ì˜ì‚¬í•­**\n\n{info['warning']}"
                                        )
                else:
                    st.warning("ë²ˆì—­ëœ íŒŒì¼ì´ ì—†ì–´ ë¦¬ì†ŒìŠ¤íŒ©ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                # ìµœì¢… ì§„í–‰ ìƒí™©
                overall_progress_bar.progress(100)
                overall_progress_text.markdown(
                    f"**{total_files}/{total_files}** (100%)"
                )
                status_text.markdown("ë²ˆì—­ ì™„ë£Œ!")

                # ìµœì¢… ì‚¬ì „ ì €ì¥
                final_dict_path = os.path.join(
                    output_path, "total_dictionary", f"{uuid_str}_final.json"
                )
                os.makedirs(os.path.dirname(final_dict_path), exist_ok=True)
                with open(final_dict_path, "w", encoding="utf-8") as f:
                    json.dump(translation_dictionary, f, ensure_ascii=False, indent=4)

                # ê²°ê³¼ í‘œì‹œ
                st.success(
                    f"ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ {len(translated_files)}ê°œì˜ íŒŒì¼ì´ ë²ˆì—­ë˜ì—ˆìŠµë‹ˆë‹¤. ë²ˆì—­ ì‚¬ì „ì€ {len(translation_dictionary)}ê°œ í•­ëª©ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
                )

                # ì˜¤ë¥˜ ë°œìƒ íŒŒì¼ í‘œì‹œ
                if failed_files:
                    with st.expander(
                        f"ì˜¤ë¥˜ ë°œìƒ íŒŒì¼ ëª©ë¡ ({len(failed_files)}ê°œ)", expanded=False
                    ):
                        for i, failed_file in enumerate(failed_files):
                            file_basename = os.path.basename(failed_file["path"])
                            st.markdown(
                                f"**{i + 1}. {file_basename}** ({failed_file['category']})"
                            )
                            st.markdown(f"  - ê²½ë¡œ: `{failed_file['path']}`")
                            st.markdown(f"  - ì˜¤ë¥˜: {failed_file['error']}")
                            st.markdown("---")

                    # ì˜¤ë¥˜ íŒŒì¼ ëª©ë¡ ì €ì¥
                    failed_list_path = os.path.join(output_path, "failed_files.json")
                    with open(failed_list_path, "w", encoding="utf-8") as f:
                        json.dump(failed_files, f, ensure_ascii=False, indent=4)

                    st.warning(
                        f"ì˜¤ë¥˜ ë°œìƒ íŒŒì¼ ëª©ë¡ì´ {failed_list_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ë“¤ì€ '__FAILED__' ì ‘ë‘ì–´ê°€ ë¶™ì€ íŒŒì¼ë¡œ ë³µì‚¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
                    )

        except Exception as e:
            error_traceback = traceback.format_exc()
            st.error(
                f"íŒŒì¼ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {str(e)}\n\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´ëŠ” ì½˜ì†” ì°½ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
            logger.error(error_traceback)


if __name__ == "__main__":
    main()
