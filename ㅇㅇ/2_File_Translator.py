import asyncio
import json
import logging
import os
import sys
import tempfile  # ì„ì‹œ íŒŒì¼ ìƒì„±ì„ ìœ„í•´ ì¶”ê°€
import time
import traceback

import streamlit as st

# Windows í™˜ê²½ì—ì„œ asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì •ì±… ì„¤ì •
if sys.platform.startswith("win"):
    import asyncio

    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())


from minecraft_modpack_auto_translator import (  # translate_json_file ì„í¬íŠ¸ ì¶”ê°€
    translate_json_file,
)
from minecraft_modpack_auto_translator.graph import (
    create_translation_graph,
    registry,
)
from minecraft_modpack_auto_translator.loaders.context import (
    TranslationContext,
)
from minecraft_modpack_auto_translator.translator import get_translator
from streamlit_utils import (
    get_delay_manager,
    get_rate_limiter,
    get_supported_extensions,
    initialize_translation_dictionary,
    load_custom_dictionary,
    render_api_key_management,
    render_custom_dictionary_upload,
    render_log_settings,
    render_model_provider_selection,
    render_model_selection,
    render_rate_limiter_settings,
    render_request_delay_settings,
    setup_logging,
)


def get_parser_by_extension(extension):
    """íŒŒì¼ í™•ì¥ìì— ë§ëŠ” íŒŒì„œ í´ë˜ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from minecraft_modpack_auto_translator.parsers.base_parser import BaseParser

    return BaseParser.get_parser_by_extension(extension)


st.set_page_config(
    page_title="ë‹¨ì¼ íŒŒì¼ ë²ˆì—­ê¸°",
    page_icon="ğŸ“„",
    layout="wide",
)

logger = logging.getLogger(__name__)
# ë””ë²„ê·¸ ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)

# ì–¸ì–´ ì½”ë“œ ì„¤ì •
LANG_CODE = os.getenv("LANG_CODE", "ko_kr")

# API í‚¤ í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ ë§¤í•‘
API_KEY_ENV_VARS = {
    "OpenAI": "OPENAI_API_KEY",
    "Google": "GOOGLE_API_KEY",
    "Grok": "GROK_API_KEY",
    "Ollama": "OLLAMA_API_KEY",
    "Anthropic": "ANTHROPIC_API_KEY",
}

# API ë² ì´ìŠ¤ URL í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ ë§¤í•‘
API_BASE_ENV_VARS = {
    "OpenAI": "OPENAI_API_BASE",
    "Google": "GOOGLE_API_BASE",
    "Grok": "GROK_API_BASE",
    "Ollama": "OLLAMA_API_BASE",
    "Anthropic": "ANTHROPIC_API_BASE",
}


def main():
    st.title("ğŸ“„ ë‹¨ì¼ íŒŒì¼ ë²ˆì—­ê¸°")
    st.markdown("JSON, LANG, SNBT í˜•ì‹ì˜ ë‹¨ì¼ ì–¸ì–´ íŒŒì¼ì„ ë²ˆì—­í•©ë‹ˆë‹¤.")

    if "api_key_index" not in st.session_state:
        st.session_state.api_key_index = 0

    st.sidebar.header("ë²ˆì—­ ì„¤ì •")

    model_provider = render_model_provider_selection()
    api_keys = render_api_key_management(model_provider)
    selected_model, api_base_url, temperature = render_model_selection(model_provider)
    use_rate_limiter, rpm = render_rate_limiter_settings(model_provider)
    use_request_delay, request_delay = render_request_delay_settings(model_provider)

    # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì • (íŒŒì¼ ë‚´ë¶€) - File Translator Specific
    st.sidebar.subheader("ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì • (íŒŒì¼ ë‚´ë¶€)")
    if model_provider == "G4F":
        file_split_number = 3
        st.sidebar.markdown("G4F ëª¨ë“œ: íŒŒì¼ ë¶„í•  ì‘ì—…ì ìˆ˜ ê³ ì • (3ê°œ)")
    else:
        file_split_number = st.sidebar.number_input(
            "íŒŒì¼ ë¶„í•  ì‘ì—…ì ìˆ˜",
            min_value=1,
            max_value=100,
            value=1,
            step=1,
            help="íŒŒì¼ ë‚´ë¶€ì˜ ë²ˆì—­ í•­ëª©ì„ ëª‡ ê°œì˜ ì‘ì—…ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ë™ì‹œì— ì²˜ë¦¬í• ì§€ ì„¤ì •í•©ë‹ˆë‹¤. ê°’ì´ ë†’ì„ìˆ˜ë¡ ë‹¨ì¼ íŒŒì¼ ë²ˆì—­ ì†ë„ê°€ ë¹¨ë¼ì§ˆ ìˆ˜ ìˆì§€ë§Œ, API ì‚¬ìš©ëŸ‰ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.",
            key="file_split_number_input",
        )

    use_random_order = st.sidebar.checkbox(
        "ëœë¤ ìˆœì„œë¡œ ë²ˆì—­",
        value=False,
        help="íŒŒì¼ ë‚´ë¶€ í•­ëª©ì„ ëœë¤ ìˆœì„œë¡œ ë²ˆì—­í•˜ì—¬ ë³‘ë ¬ ë²ˆì—­ ì‹œ ì‚¬ì „ì˜ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.",
        key="random_order_checkbox",
    )

    max_log_lines = render_log_settings()
    custom_dict_file = render_custom_dictionary_upload()
    # --- End Sidebar Settings ---

    # --- ë©”ì¸ í™”ë©´ ---
    col1, col2 = st.columns(2)
    with col1:
        source_lang_code = st.text_input(
            "ì›ë³¸ ì–¸ì–´ ì½”ë“œ", "en_us", key="source_lang_input"
        ).lower()

    supported_extensions = get_supported_extensions()
    uploaded_file = st.file_uploader(
        f"ë²ˆì—­í•  ì–¸ì–´ íŒŒì¼ ì—…ë¡œë“œ ({', '.join(supported_extensions)})",
        type=[ext.lstrip(".") for ext in supported_extensions],
        key="file_uploader",
    )

    target_lang_code = LANG_CODE
    # ì‚¬ì „ ì´ˆê¸°í™” ë° ë¡œë“œ (streamlit_utils ì‚¬ìš©)
    translation_dictionary, translation_dictionary_lowercase = (
        initialize_translation_dictionary(source_lang_code, target_lang_code)
    )
    translation_dictionary, translation_dictionary_lowercase = load_custom_dictionary(
        custom_dict_file, translation_dictionary, translation_dictionary_lowercase
    )

    # ë²ˆì—­ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ë²ˆì—­ ì‹œì‘"):
        if not api_keys and model_provider != "G4F":
            st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()

        if uploaded_file is None:
            st.error("ë²ˆì—­í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()

        # ë¡œê¹… í•¸ë“¤ëŸ¬ ì„¤ì • ë° UI í‘œì‹œ (ìˆ˜ì •/ì¶”ê°€ëœ ë¶€ë¶„)
        log_session_key = "file_translator_logs"  # íŒŒì¼ë³„ ê³ ìœ  í‚¤
        log_handler = setup_logging(
            max_log_lines=max_log_lines, session_key=log_session_key
        )

        # ë¡œê·¸ ì„¸ì…˜ ìƒíƒœ í‚¤ ëª…ì‹œì  ì´ˆê¸°í™” (KeyError ë°©ì§€)
        if log_session_key not in st.session_state:
            st.session_state[log_session_key] = []

        # ë¡œê·¸ë¥¼ í‘œì‹œí•  UI ì˜ì—­ ìƒì„±
        log_container = st.expander("ë²ˆì—­ ë¡œê·¸", expanded=True)
        with log_container:
            log_messages_to_display = st.session_state[log_session_key]
            log_area = st.markdown(
                "  \n".join(log_messages_to_display), unsafe_allow_html=True
            )
            if st.button("ë¡œê·¸ ì§€ìš°ê¸°", key="clear_log_button_file"):  # ë²„íŠ¼ í‚¤ ì¶”ê°€
                if log_handler:
                    log_handler.clear_logs()
                    st.rerun()

        try:
            with st.spinner("ë²ˆì—­ ì§„í–‰ ì¤‘..."):
                st.subheader("ë²ˆì—­ ì§„í–‰ ìƒí™©")
                progress_bar = st.progress(0)
                progress_text = st.empty()
                status_text = st.empty()

                status_text.text("ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
                logger.info("ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")

                st.session_state.api_key_index = 0
                total_api_keys = len(api_keys) if api_keys else 1
                logger.info(f"ì´ {total_api_keys}ê°œì˜ API í‚¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

                # Rate Limiter ë° Delay Manager ìƒì„± (streamlit_utils ì‚¬ìš©)
                rate_limiter = get_rate_limiter(
                    use_rate_limiter and model_provider != "G4F", rpm
                )
                if rate_limiter:
                    logger.info(f"ì†ë„ ì œí•œ ì„¤ì •: {rpm} RPM ({rpm / 60.0:.2f} RPS)")

                g4f_delay = 1.0 if model_provider == "G4F" else 0
                effective_delay = (
                    request_delay
                    if use_request_delay and model_provider != "G4F"
                    else g4f_delay
                )
                delay_manager = get_delay_manager(effective_delay > 0, effective_delay)
                if effective_delay > 0:
                    logger.info(f"ìš”ì²­ ë”œë ˆì´ ì„¤ì •: {effective_delay:.1f}ì´ˆ")

                # ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                shared_context = TranslationContext(
                    translation_graph=create_translation_graph(),
                    custom_dictionary_dict=translation_dictionary,
                    registry=registry,
                )
                shared_context.initialize_dictionaries()
                dict_len = len(shared_context.get_dictionary())
                logger.info(f"ë²ˆì—­ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ: {dict_len}ê°œ ì‚¬ì „ í•­ëª©")

                # íŒŒì¼ ë‚´ìš© ì½ê¸° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                file_content_bytes = uploaded_file.getvalue()
                try:
                    file_content_str = file_content_bytes.decode("utf-8")
                except UnicodeDecodeError:
                    st.error("íŒŒì¼ ì¸ì½”ë”© ì˜¤ë¥˜: UTF-8 í˜•ì‹ì˜ íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
                    st.stop()

                # ì…ë ¥ ë°ì´í„° íŒŒì‹± (streamlit_utils ì‚¬ìš© -> ì´ì œ translate_json_fileì´ ì²˜ë¦¬)
                # input_data = extract_lang_content(uploaded_file, file_content_str)
                # if not isinstance(input_data, dict):
                #     st.error(
                #         "íŒŒì¼ ë‚´ìš©ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§€ì›ë˜ëŠ” í˜•ì‹(JSON, LANG, SNBT)ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                #     )
                #     st.stop()

                start_time = time.time()
                # total_items ëŠ” translate_single_file ë‚´ì—ì„œ ê³„ì‚°í•˜ë„ë¡ ë³€ê²½
                # processed_items = 0

                async def update_progress(
                    done=False, total_items=None, processed_items=None
                ):
                    # nonlocal processed_items -> ì´ í•¨ìˆ˜ëŠ” ì´ì œ worker ì½œë°±ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
                    current_time = time.time()
                    progress_percent = 0
                    items_info = ""

                    if total_items is not None and processed_items is not None:
                        progress_percent = (
                            int((processed_items / total_items) * 95)
                            if total_items > 0 and not done
                            else 100
                        )
                        items_info = f"**{processed_items}/{total_items}** í•­ëª© "

                    progress_bar.progress(progress_percent)
                    progress_text.markdown(f"{items_info}({progress_percent}%) ")

                    elapsed_time = current_time - start_time
                    hours, rem = divmod(elapsed_time, 3600)
                    mins, secs = divmod(rem, 60)
                    elapsed_str = f"{int(hours):02}:{int(mins):02}:{int(secs):02}"

                    status_msg = (
                        f"ë²ˆì—­ ì™„ë£Œ! ì´ ê²½ê³¼ ì‹œê°„: {elapsed_str}"
                        if done
                        else f"ë²ˆì—­ ì¤‘... ê²½ê³¼ ì‹œê°„: {elapsed_str}"
                    )
                    status_text.markdown(status_msg)

                # translate_json_file ë‚´ë¶€ ì½œë°± í•¨ìˆ˜
                processed_items_count = 0
                total_items_count = 0

                async def worker_progress_callback():
                    nonlocal processed_items_count, total_items_count
                    if total_items_count > 0:
                        processed_items_count = min(
                            processed_items_count + 1, total_items_count - 1
                        )
                        await update_progress(
                            done=False,
                            total_items=total_items_count,
                            processed_items=processed_items_count,
                        )

                async def translate_single_file():
                    nonlocal \
                        translation_dictionary, \
                        processed_items_count, \
                        total_items_count
                    temp_input_file = None
                    translated_data_dict = None  # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
                    translated_content_str = None  # ê²°ê³¼ ë¬¸ìì—´
                    try:
                        # ì›ë³¸ íŒŒì¼ ë‚´ìš©ìœ¼ë¡œ ì„ì‹œ ì…ë ¥ íŒŒì¼ ìƒì„±
                        with tempfile.NamedTemporaryFile(
                            delete=False,
                            mode="w",
                            encoding="utf-8",
                            suffix=os.path.splitext(uploaded_file.name)[1],
                        ) as tmp_f:
                            # ì›ë³¸ íŒŒì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ ë‚´ìš©ì„ í•œë²ˆ íŒŒì‹±í•˜ê³  ë‹¤ì‹œ ì €ì¥ (ì •ê·œí™” ëª©ì )
                            try:
                                file_ext = os.path.splitext(uploaded_file.name)[
                                    1
                                ].lower()
                                parser = get_parser_by_extension(file_ext)
                                if parser:
                                    original_data = parser.load(file_content_str)
                                    # total_items_count ì„¤ì •
                                    if isinstance(original_data, dict):
                                        total_items_count = len(original_data)
                                    # ì›ë³¸ íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì €ì¥
                                    normalized_content = parser.save(original_data)
                                    tmp_f.write(normalized_content)
                                else:
                                    # íŒŒì„œ ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                                    tmp_f.write(file_content_str)
                                    # ì›ë³¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ëµì ì¸ í•­ëª© ìˆ˜ ê³„ì‚° (JSON, LANGë§Œ)
                                    if file_ext == ".json":
                                        try:
                                            total_items_count = len(
                                                json.loads(file_content_str)
                                            )
                                        except json.JSONDecodeError:
                                            total_items_count = (
                                                file_content_str.count("\n") + 1
                                            )
                                    elif file_ext in [".lang", ".txt"]:
                                        total_items_count = (
                                            file_content_str.count("\n") + 1
                                        )
                                    else:
                                        total_items_count = 1  # ì•Œ ìˆ˜ ì—†ì„ ë•Œ ê¸°ë³¸ê°’

                            except Exception as parse_err:
                                logger.warning(
                                    f"ì›ë³¸ íŒŒì¼ ì •ê·œí™” ì¤‘ ì˜¤ë¥˜: {parse_err}, ì›ë³¸ ë‚´ìš© ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."
                                )
                                tmp_f.write(file_content_str)
                                # ì›ë³¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ëµì ì¸ í•­ëª© ìˆ˜ ê³„ì‚° (JSON, LANGë§Œ)
                                file_ext = os.path.splitext(uploaded_file.name)[
                                    1
                                ].lower()
                                if file_ext == ".json":
                                    try:
                                        total_items_count = len(
                                            json.loads(file_content_str)
                                        )
                                    except json.JSONDecodeError:
                                        total_items_count = (
                                            file_content_str.count("\n") + 1
                                        )
                                elif file_ext in [".lang", ".txt"]:
                                    total_items_count = file_content_str.count("\n") + 1
                                else:
                                    total_items_count = 1  # ì•Œ ìˆ˜ ì—†ì„ ë•Œ ê¸°ë³¸ê°’

                            temp_input_file = tmp_f.name
                        logger.info(f"ì„ì‹œ ì…ë ¥ íŒŒì¼ ìƒì„±: {temp_input_file}")

                        # ì„ì‹œ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìƒì„± (JSONìœ¼ë¡œ ì €ì¥ë  ì˜ˆì •)
                        temp_output_dir = tempfile.mkdtemp()
                        temp_output_file = os.path.join(
                            temp_output_dir,
                            f"translated_{os.path.splitext(uploaded_file.name)[0]}.json",
                        )  # í™•ì¥ì .json
                        logger.info(f"ì„ì‹œ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ: {temp_output_file}")

                        current_api_key_index = st.session_state.api_key_index
                        current_api_key = (
                            api_keys[current_api_key_index % total_api_keys]
                            if api_keys
                            else None
                        )

                        st.session_state.api_key_index = (
                            (current_api_key_index + 1) % total_api_keys
                            if api_keys and total_api_keys > 0
                            else 0
                        )

                        logger.info(
                            f"API í‚¤ ì‚¬ìš© ì¤‘: {current_api_key_index + 1}/{total_api_keys}"
                        )

                        processed_items_count = 0  # ì½œë°±ìš© ì¹´ìš´í„° ì´ˆê¸°í™”
                        # translate_dict ëŒ€ì‹  translate_json_file í˜¸ì¶œ
                        final_dictionary = await translate_json_file(  # í•¨ìˆ˜ ì´ë¦„ ë³€ê²½ ë° ì¸ì ìˆ˜ì •
                            input_path=temp_input_file,
                            output_path=temp_output_file,  # ì¶œë ¥ ê²½ë¡œ ì¶”ê°€ (JSONìœ¼ë¡œ ì €ì¥ë¨)
                            custom_dictionary_dict=shared_context.get_dictionary(),
                            llm=get_translator(
                                provider=model_provider.lower(),
                                api_key=current_api_key,
                                model_name=selected_model,
                                api_base=api_base_url,
                                temperature=temperature,
                                rate_limiter=rate_limiter,
                            ),
                            max_workers=file_split_number,
                            progress_callback=worker_progress_callback,  # ë‚´ë¶€ ì½œë°± í•¨ìˆ˜ ì‚¬ìš©
                            external_context=shared_context,
                            delay_manager=delay_manager,
                            use_random_order=use_random_order,
                            # target_lang_code ëŠ” translate_json_file ì— ì—†ìŒ
                        )

                        translation_dictionary = final_dictionary  # ìµœì¢… ì‚¬ì „ ì—…ë°ì´íŠ¸

                        # ë²ˆì—­ëœ JSON íŒŒì¼ ë‚´ìš© ì½ê³  ì›ë³¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        if os.path.exists(temp_output_file):
                            with open(temp_output_file, "r", encoding="utf-8") as f:
                                translated_json_content = f.read()

                            # JSON íŒŒì‹±
                            try:
                                translated_data_dict = json.loads(
                                    translated_json_content
                                )
                            except json.JSONDecodeError as json_err:
                                logger.error(f"ë²ˆì—­ ê²°ê³¼ JSON íŒŒì‹± ì˜¤ë¥˜: {json_err}")
                                st.error(
                                    f"ë²ˆì—­ ê²°ê³¼ íŒŒì¼(JSON)ì„ íŒŒì‹±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {json_err}"
                                )
                                raise  # ì˜¤ë¥˜ ë°œìƒ ì‹œ í•¨ìˆ˜ ì¤‘ë‹¨

                            # ì›ë³¸ íŒŒì¼ í™•ì¥ìì— ë§ëŠ” íŒŒì„œ ê°€ì ¸ì˜¤ê¸°
                            file_ext = os.path.splitext(uploaded_file.name)[1].lower()
                            parser = get_parser_by_extension(file_ext)

                            if parser:
                                # íŒŒì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
                                translated_content_str = parser.save(
                                    translated_data_dict
                                )
                            else:
                                logger.warning(
                                    f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í™•ì¥ì({file_ext})ì˜ ê²°ê³¼ íŒŒì„œ ì—†ìŒ. JSON ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."
                                )
                                # íŒŒì„œê°€ ì—†ìœ¼ë©´ JSON ë¬¸ìì—´ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë‹¤ìš´ë¡œë“œìš©)
                                translated_content_str = translated_json_content

                        else:
                            logger.error(
                                f"ë²ˆì—­ ê²°ê³¼ íŒŒì¼({temp_output_file})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            )
                            st.error("ë²ˆì—­ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                            raise FileNotFoundError(
                                "Translated file not found"
                            )  # ì˜¤ë¥˜ ë°œìƒ ì‹œ í•¨ìˆ˜ ì¤‘ë‹¨

                        await update_progress(
                            done=True,
                            total_items=total_items_count,
                            processed_items=total_items_count,
                        )  # ìµœì¢… ì™„ë£Œ ì—…ë°ì´íŠ¸

                        # ê²°ê³¼ ë°˜í™˜ (ë”•ì…”ë„ˆë¦¬, ë¬¸ìì—´)
                        return translated_data_dict, translated_content_str

                    except Exception as e:
                        logger.error(f"íŒŒì¼ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        logger.error(traceback.format_exc())
                        st.error(f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                        await update_progress(
                            done=True,
                            total_items=total_items_count,
                            processed_items=processed_items_count,
                        )  # ì˜¤ë¥˜ ì‹œì—ë„ ì™„ë£Œ ì²˜ë¦¬
                        return None, None  # ì˜¤ë¥˜ ì‹œ None ë°˜í™˜
                    finally:
                        # ì„ì‹œ íŒŒì¼ ë° ë””ë ‰í† ë¦¬ ì‚­ì œ
                        if temp_input_file and os.path.exists(temp_input_file):
                            try:
                                os.remove(temp_input_file)
                                logger.info(f"ì„ì‹œ ì…ë ¥ íŒŒì¼ ì‚­ì œ: {temp_input_file}")
                            except Exception as e:
                                logger.warning(f"ì„ì‹œ ì…ë ¥ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
                        if "temp_output_dir" in locals() and os.path.exists(
                            temp_output_dir
                        ):
                            try:
                                import shutil

                                shutil.rmtree(temp_output_dir)
                                logger.info(
                                    f"ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì‚­ì œ: {temp_output_dir}"
                                )
                            except Exception as e:
                                logger.warning(f"ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")

                # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰ ë° ê²°ê³¼ ë°›ê¸°
                translated_data_dict, translated_content_for_download = asyncio.run(
                    translate_single_file()
                )

                if (
                    translated_data_dict and translated_content_for_download
                ):  # ë‘ ê²°ê³¼ ëª¨ë‘ ì •ìƒì¼ ë•Œ
                    st.subheader("ğŸ¯ ë²ˆì—­ ê²°ê³¼")

                    # translated_content_for_download ë¥¼ ì§ì ‘ ì‚¬ìš©
                    if translated_content_for_download:
                        translated_filename = f"{os.path.splitext(uploaded_file.name)[0]}_{target_lang_code}{os.path.splitext(uploaded_file.name)[1]}"
                        st.download_button(
                            label=f"ğŸ’¾ ë²ˆì—­ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ({translated_filename})",
                            data=translated_content_for_download.encode(
                                "utf-8"
                            ),  # ì—¬ê¸°ì„œ ì¸ì½”ë”©
                            file_name=translated_filename,
                            mime="text/plain",
                            key="download_translated_button",
                        )
                    else:
                        st.warning(
                            "ë²ˆì—­ ê²°ê³¼ëŠ” ìƒì„±ë˜ì—ˆìœ¼ë‚˜ ë‹¤ìš´ë¡œë“œìš© ë¬¸ìì—´ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                        )

                    if translation_dictionary:
                        updated_dict_json = json.dumps(
                            translation_dictionary, ensure_ascii=False, indent=4
                        )
                        st.download_button(
                            label=f"ğŸ“š ì—…ë°ì´íŠ¸ëœ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ ({len(translation_dictionary)}ê°œ í•­ëª©)",
                            data=updated_dict_json.encode("utf-8"),
                            file_name="updated_dictionary.json",
                            mime="application/json",
                            key="download_dict_button",
                        )

                    st.success("íŒŒì¼ ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                elif (
                    translated_data_dict is None
                    and translated_content_for_download is None
                ):
                    # translate_single_file ì—ì„œ ì´ë¯¸ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë©”ì‹œì§€ í‘œì‹œë¨
                    st.info("ë²ˆì—­ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ê²°ê³¼ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ì˜ˆìƒì¹˜ ëª»í•œ ê²½ìš° (í•œìª½ë§Œ None)
                    st.error("ë²ˆì—­ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ë²ˆì—­ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(traceback.format_exc())
        finally:
            # Log handler removal
            if "log_handler" in locals() and log_handler:
                try:
                    root_logger = logging.getLogger()
                    if log_handler in root_logger.handlers:
                        root_logger.removeHandler(log_handler)
                    modpack_logger = logging.getLogger(
                        "minecraft_modpack_auto_translator"
                    )
                    if log_handler in modpack_logger.handlers:
                        modpack_logger.removeHandler(log_handler)
                except Exception as e:
                    logger.warning(f"ë¡œê·¸ í•¸ë“¤ëŸ¬ ì œê±° ì¤‘ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main()
